# -*- coding: utf-8 -*-
"""Education Predictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PipOyKiBFRd3woe8Od6Xbn8RdZp6c-CU
"""

!pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

# fetch dataset
student_performance = fetch_ucirepo(id=320)

# data (as pandas dataframes)
X = student_performance.data.features
y = student_performance.data.targets

# metadata
print(student_performance.metadata)

# variable information
print(student_performance.variables)

X

y

from ucimlrepo import fetch_ucirepo
import pandas as pd
import seaborn as sns

# sns.set_theme(style="ticks")
education_indicators = fetch_ucirepo(id=320)
X = education_indicators.data.features
y = education_indicators.data.targets

df1 = X #[['Age', 'BMI', 'MentHlth', 'PhysHlth']]
df2 = y["Diabetes_binary"]
df1["Diabetes_binary"] = df2
#sns.pairplot(df1, hue="Diabetes_binary", plot_kws={'alpha': 0.2})
#sns.pairplot(df, kind='reg', plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}})

sns.histplot(data=df1, x="BMI", hue="Diabetes_binary", multiple="dodge", shrink=.8, bins=7)

sns.histplot(data=df1, x="MentHlth", hue="Diabetes_binary", multiple="dodge", shrink=.8, bins=7)

sns.histplot(data=df1, x="PhysHlth", hue="Diabetes_binary", multiple="dodge", shrink=.8, bins=7)

sns.histplot(data=df1, x="Age", hue="Diabetes_binary", multiple="dodge", shrink=.8, bins=13)

from sklearn.metrics import confusion_matrix as cm

features = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex']

counts = df1['Diabetes_binary'].value_counts()
print(counts)

for feature in features:
  print(feature)
  result = cm(df1['Diabetes_binary'], df1[feature])
  print("For Diabetes = No")
  value = result[0][0]/(result[0][0]+result[0][1])
  print(value, 1.0 - value)
  print("For Diabetes = Yes")
  value = result[1][0]/(result[1][0]+result[0][1])
  print(value, 1.0 - value)
  value0 = result[0][0]+result[1][0]
  value1 = result[0][1]+result[1][1]
  print(value0/(value0+value1), value1/(value0+value1))
  print("\n\n")

from multiprocessing import Array
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import ListedColormap
from sklearn.model_selection import cross_val_score
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_circles, make_classification, make_moons
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

names = [
    "Nearest Neighbors",
    "Linear SVM",
    "Decision Tree",
    "Logistic Regression",
    "Random Forest",
    "AdaBoost",
    "Naive Bayes",
    "QDA",
]

classifiers = [
    KNeighborsClassifier(n_neighbors=10), # 10 neighbors
    LinearSVC(random_state=0),
    DecisionTreeClassifier(max_depth=None, random_state=0),
    LogisticRegression(random_state=0),
    RandomForestClassifier(
        max_depth=None, n_estimators=100, random_state=0
    ),
    AdaBoostClassifier(algorithm="SAMME", random_state=0),
    GaussianNB(),
    QuadraticDiscriminantAnalysis(),
]
array = []
cv_folds = 10